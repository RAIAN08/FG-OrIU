{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import os\n",
    "\n",
    "current_file_path = os.path.abspath(\"__file__\")\n",
    "current_folder = os.path.dirname(current_file_path)\n",
    "parent_folder = os.path.dirname(current_folder)\n",
    "os.chdir(parent_folder)\n",
    "\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, name):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(name, \"a\")\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)  \n",
    "\n",
    "    def flush(self):\n",
    "        self.log.flush()\n",
    "\n",
    "        \n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import sys\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from vit_pytorch_face import ViT_face, ViT_face_low, ViT_face_up\n",
    "from vit_pytorch_face import ViTs_face\n",
    "from vit_pytorch_face import ModifiedViT\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from util.utils import (\n",
    "    calculate_prototypes,\n",
    "    AverageMeter,\n",
    "    train_accuracy,\n",
    "    get_unique_classes,\n",
    "    replace_ffn_with_lora,\n",
    "    modify_head,\n",
    ")\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "\n",
    "\n",
    "def get_cls_token_output(model, x, block_idx=11):\n",
    "    _, features, embed =  model(x.float(), label=1, prepare_feature=True, training=True)\n",
    "    xxx = features[\"layer_{}_ff\".format(block_idx)][:,:,:]\n",
    "\n",
    "    return  xxx \n",
    "\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    tensor = tensor.cuda()\n",
    "    mean = torch.tensor(mean).view(1, 3, 1, 1).to(tensor.device)\n",
    "    std = torch.tensor(std).view(1, 3, 1, 1).to(tensor.device)\n",
    "    tensor = tensor * std + mean\n",
    "    return torch.clamp(tensor, 0, 1) \n",
    "\n",
    "\n",
    "def normalize(tensor, mean, std):\n",
    "    mean = torch.tensor(mean).view(1, 3, 1, 1).cuda()\n",
    "    std = torch.tensor(std).view(1, 3, 1, 1).cuda()\n",
    "    return (tensor - mean) / std\n",
    "\n",
    "\n",
    "def loss_function(generated_img, target_features, model, block_idx):\n",
    "\n",
    "    generated_img_normalized = normalize(generated_img, IMAGENET_MEAN, IMAGENET_STD)\n",
    "    model_output = get_cls_token_output(model, generated_img_normalized, block_idx)\n",
    "    return F.mse_loss(model_output, target_features), model_output\n",
    "\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "BACKBONE_DICT = {\n",
    "    \"VIT_B16\": replace_ffn_with_lora(\n",
    "        ModifiedViT(vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)),\n",
    "        rank=8,\n",
    "    ),\n",
    "}\n",
    "\n",
    "model = BACKBONE_DICT[\"VIT_B16\"].cuda()\n",
    "\n",
    "\n",
    "# Mean and standard deviation of ImageNet dataset\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),  # Adjust the short side to 256\n",
    "        transforms.CenterCrop(224),  # Center cropped to 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ]\n",
    ")\n",
    "# Load ImageNet official category labels (fixed order)\n",
    "IMAGENET_CLASSES_PATH = \"data/imagenet100/imagenet_classes.txt\"\n",
    "assert os.path.exists(\n",
    "    IMAGENET_CLASSES_PATH\n",
    "), \"Please download the ImageNet class label file imagenet_classes.txt!\"\n",
    "with open(IMAGENET_CLASSES_PATH) as f:\n",
    "    imagenet_classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "\n",
    "DATA_ROOT = './data/imagenet100'\n",
    "imagenet_test_dataset = ImageFolder(\n",
    "    root=os.path.join(DATA_ROOT, \"test\"), transform=data_transform\n",
    ")\n",
    "# Check the order of categories loaded by ImageFolder\n",
    "test_classes = list(\n",
    "    imagenet_test_dataset.class_to_idx.keys()\n",
    ")  # Category names sorted lexicographically\n",
    "assert set(test_classes).issubset(\n",
    "    set(imagenet_classes)\n",
    "), \"Test set category is not in ImageNet category!\"\n",
    "# Get the mapping of the current category ID to the original ImageNet category ID\n",
    "imagenet_class_to_idx = {\n",
    "    cls_name: idx for idx, cls_name in enumerate(imagenet_classes)\n",
    "}\n",
    "current_id_to_original_id = {\n",
    "    imagenet_test_dataset.class_to_idx[cls]: imagenet_class_to_idx[cls]\n",
    "    for cls in imagenet_test_dataset.classes\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model = modify_head(\n",
    "    model, current_id_to_original_id=current_id_to_original_id\n",
    ").cuda()\n",
    "\n",
    "\n",
    "cos_sim = True\n",
    "if cos_sim:\n",
    "    import copy\n",
    "    copy_model = copy.deepcopy(model)\n",
    "\n",
    "BACKBONE_RESUME_ROOT = None\n",
    "# old\n",
    "\n",
    "switch_list = ['ours', 'gslora', 'der++', 'der', 'fdr', 'lwf', 'scrub', 'scrub-u', 'ewc']\n",
    "\n",
    "for switch in switch_list:\n",
    "\n",
    "    # switch =  'ours'\n",
    "    # switch =  'gslora'\n",
    "    # switch =  'der++'\n",
    "    # switch =  'der'\n",
    "    # switch =  'fdr'\n",
    "    # switch =  'lwf'\n",
    "    # switch =  'scrub'\n",
    "    # switch =  'scrub-u'\n",
    "    # switch =  'ewc'\n",
    "    if switch == 'gt':\n",
    "        pass\n",
    "    elif switch == 'gslora':\n",
    "        BACKBONE_RESUME_ROOT = './all_baseline/witho_ema/exps_image/no-ema-proto/CLGSLoRA/start80forgetper20lr1e-2beta0.15-20250103155818/task-level/Backbone_task_0.pth'\n",
    "    elif switch == 'ours':\n",
    "        BACKBONE_RESUME_ROOT = './LOG/test_image100/4types/20250218/type1_lw2g_back_df_nogumble_searchparams_20240216/lw2g_dr-01_df-005/exps_image/multistep/CLGSLoRA_pure_celoss-dr-coef_1/start80forgetper20lr1e-2beta0.15-20250218114731/task-level/Backbone_task_0.pth'\n",
    "    elif switch == \"der++\":\n",
    "        BACKBONE_RESUME_ROOT = './exps_image/forget-CL/CL-baseline/DER++0.5-start80forget20lr1e-4-20250223225436/task-level/Backbone_task_0.pth'\n",
    "    elif switch == 'der':\n",
    "        BACKBONE_RESUME_ROOT = './exps_image/forget-CL/CL-baseline/DER0.1-start80forget20lr1e-4-20250223225436/task-level/Backbone_task_0.pth'\n",
    "    elif switch == 'fdr':\n",
    "        BACKBONE_RESUME_ROOT = './exps_image/forget-CL/CL-baseline/FDR10-start80forget20lr1e-3-20250223225436/task-level/Backbone_task_0.pth'\n",
    "    elif switch == 'lwf':\n",
    "        BACKBONE_RESUME_ROOT = './exps_image/forget-CL/CL-baseline/Lwf10-start80forget20lr1e-4-20250223225436/task-level/Backbone_task_0.pth'\n",
    "    elif switch == 'scrub':\n",
    "        BACKBONE_RESUME_ROOT = './exps_image/forget-CL-baseline/CL-baseline-one/SCRUB-start80forget20lr1e-4-20250223225436/task-level/Backbone_task_0.pth'\n",
    "    elif switch == 'scrub-u':\n",
    "        BACKBONE_RESUME_ROOT = './exps_image/forget-CL-baseline/CL-baseline-one/SCRUBsmooth-start80forget20lr1e-4-20250223225436/task-level/Backbone_task_0.pth'\n",
    "    elif switch == 'ewc':\n",
    "        BACKBONE_RESUME_ROOT ='./LOG/exps_image/multistep/forget-CL/CL-baseline/EWC10-start80forget20lr1e-4-20250212002751/task-level/Backbone_task_0.pth'\n",
    "    # BACKBONE_RESUME_ROOT = './all_baseline/witho_ema/exps_image/no-ema-proto/CLGSLoRA/start80forgetper20lr1e-2beta0.15-20250103155818/task-level/Backbone_task_0.pth'\n",
    "    print('===========strat_resume')\n",
    "\n",
    "    print('BACKBONE_RESUME_ROOT', BACKBONE_RESUME_ROOT)\n",
    "    if BACKBONE_RESUME_ROOT:\n",
    "        print(\"=\" * 60)\n",
    "        print(BACKBONE_RESUME_ROOT)\n",
    "        if os.path.isfile(BACKBONE_RESUME_ROOT):\n",
    "            print(\"Loading Backbone Checkpoint '{}'\".format(BACKBONE_RESUME_ROOT))\n",
    "            missing_keys, unexpected_keys = model.load_state_dict(\n",
    "                torch.load(BACKBONE_RESUME_ROOT), strict=False\n",
    "            )\n",
    "            if len(missing_keys) > 0:\n",
    "                print(\"Missing keys: {}\".format(missing_keys))\n",
    "                print(\"\\n\")\n",
    "                for missing_key in missing_keys:\n",
    "                    if \"lora\" not in missing_key:\n",
    "                        print(\"\\033[31mWrong resume.\\033[0m\")\n",
    "                        exit()\n",
    "            if len(unexpected_keys) > 0:\n",
    "                print(\"Unexpected keys: {}\".format(unexpected_keys))\n",
    "                print(\"\\n\")\n",
    "        else:\n",
    "            print(\n",
    "                \"No Checkpoint Found at '{}' . Please Have a Check or Continue to Train from Scratch\".format(\n",
    "                    BACKBONE_RESUME_ROOT\n",
    "                )\n",
    "            )\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    img_path = './data/imagenet100/train/n02037110/n02037110_920.JPEG' # 小鸟在海上\n",
    "\n",
    "    save_path = './dip/0307/dip_result/dip_last/image/r_n01685808_499/{}/{}/'.format(switch, block_idx)\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    log_out = save_path + 'output.log'   \n",
    "    sys.stdout = Logger(log_out)\n",
    "    img = Image.open(img_path)\n",
    "    print('img', img.size)\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    img_tensor = preprocess(img).unsqueeze(0).cuda().requires_grad_(False) \n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        target_features = get_cls_token_output(model, img_tensor, block_idx).detach().cuda()  \n",
    "\n",
    "\n",
    "    if cos_sim:\n",
    "        with torch.no_grad():\n",
    "            gt_features = get_cls_token_output(copy_model, img_tensor, block_idx).detach().cuda() \n",
    "            copy_gt_features = copy.deepcopy(gt_features)\n",
    "\n",
    "\n",
    "    # 初始化噪声：假设噪声的维度为 (1, 3, 224, 224) 即224x224图像\n",
    "    noise = torch.randn_like(img_tensor, requires_grad=False).cuda()\n",
    "\n",
    "\n",
    "    autoencoder = Autoencoder().cuda()\n",
    "    optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "    num_iterations = 9100\n",
    "    for i in range(num_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        generated_img = autoencoder(noise)\n",
    "        \n",
    "        loss, embed = loss_function(generated_img, target_features, model, block_idx)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 2000 == 1000:\n",
    "            print(f\"Iteration {i}, Loss: {loss.item()}\")\n",
    "            \n",
    "\n",
    "            copy_embed = embed.detach().clone()\n",
    "            print('embed', copy_embed.shape)\n",
    "            print('copy_gt_features', copy_gt_features.shape)\n",
    "            similarity = F.cosine_similarity(copy_embed[:,0,:], copy_gt_features[:,0,:], dim=1)\n",
    "            print(f\"Cosine Similarity: {similarity.item():.4f}\")\n",
    "\n",
    "            generated_img = generated_img.detach().clamp(0, 1) \n",
    "\n",
    "\n",
    "            original_img_denorm = denormalize(img_tensor.detach(), IMAGENET_MEAN, IMAGENET_STD).clamp(0, 1)\n",
    "\n",
    "\n",
    "            generated_img_np = generated_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "            original_img_np = original_img_denorm.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "\n",
    "            ssim_score = ssim(original_img_np, generated_img_np, data_range=1, win_size=11, channel_axis=2)\n",
    "            psnr_score = psnr(original_img_np, generated_img_np, data_range=1.0)\n",
    "\n",
    "\n",
    "            print(f\"SSIM: {ssim_score:.4f}, PSNR: {psnr_score:.2f} dB\")\n",
    "\n",
    "            generated_img = generated_img.squeeze(0)  \n",
    "            generated_img = generated_img.permute(1, 2, 0)  \n",
    "            generated_img = generated_img.cpu().numpy()  \n",
    "\n",
    "\n",
    "            generated_img = generated_img.astype('float32')\n",
    "\n",
    "\n",
    "            plt.imshow(generated_img)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.savefig(save_path + 'generated_image_{}.png'.format(i), format='png', bbox_inches='tight')  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conti-forget_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
